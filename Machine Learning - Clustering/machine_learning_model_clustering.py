# -*- coding: utf-8 -*-
"""Machine Learning Model - Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DQNQcni4fBk4I6_G14y3Id5J0-uDUlMf

# CUSTOMER SEGMENTATION MODEL

# DATA PREPROCESSING

## IMPORT LIBRARIES
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.cluster import KMeans

"""## LOAD DATA"""

# Customer
df1 = pd.read_csv('drive/MyDrive/DATA SCIENCE PORTFOLIO/PBI - KALBE NUTRITIONALS - DATA SCIENTIST/Minggu 4 - Final Project/Customer.csv')

# Store
df2 = pd.read_csv('drive/MyDrive/DATA SCIENCE PORTFOLIO/PBI - KALBE NUTRITIONALS - DATA SCIENTIST/Minggu 4 - Final Project/Store.csv')

# Product
df3 = pd.read_csv('drive/MyDrive/DATA SCIENCE PORTFOLIO/PBI - KALBE NUTRITIONALS - DATA SCIENTIST/Minggu 4 - Final Project/Product.csv')

# Transaction
df4 = pd.read_csv('drive/MyDrive/DATA SCIENCE PORTFOLIO/PBI - KALBE NUTRITIONALS - DATA SCIENTIST/Minggu 4 - Final Project/Transaction.csv')

"""## MERGE DATA"""

# Transcation with Customer
df = df4.merge(df1, left_on='CustomerID', right_on='CustomerID')
df.head()

# Transcation with Customer
df = df.merge(df3, left_on='ProductID', right_on='ProductID')
df.head()

# Transcation with Store
df = df.merge(df2, left_on='StoreID', right_on='StoreID')
df.head()

"""## CHECK MISSING VALUES"""

df.isnull().sum()

# Fill missing values with modes
df['Marital Status'].fillna(df['Marital Status'].mode()[0], inplace=True)

"""## CHECK DUPLICATED VALUES"""

df.duplicated().sum()

"""## DROP REDUNDANT COLUMNS"""

df.head()

# Drop ID's columns because it does not have any meaning
df = df.drop(['ProductID', 'StoreID'], axis=1)

"""## ENCODING"""

df.head()

from sklearn.preprocessing import LabelEncoder

categorical_columns=['Marital Status','Product Name','StoreName','GroupStore','Type', 'Longitude','Latitude']
for col in categorical_columns:
    # make the encoder
    encoder = LabelEncoder()
    # fit the encoder with col we want to label for information good
    encoder.fit(df[col])
    # print information
    print('Column:', col)
    print('Original categories:', encoder.classes_)
    print('Encoded values:', encoder.transform(encoder.classes_))
    print('\n')
    # fit transform to apply the label
    df[col] = encoder.fit_transform(df[col])

"""## DATA TRANSFORMATION"""

df.head()

df.info()

# Change Date to datetime
df = df.astype({
    'Date':'datetime64[ns]'
})

# Change Income
df['Income'] = df['Income'].str.replace(',', '.')
df = df.astype({
    'Income':'float64'
})

"""## OUTLIERS"""

from scipy import stats

# Using z-score to find outliers and removes it
print(f'Jumlah baris sebelum memfilter outlier: {len(df)}')

filtered_entries = np.array([True] * len(df))
for col in ['Price_x', 'Qty', 'TotalAmount', 'Age', 'Gender', 'Income', 'Price_y']:
    zscore = abs(stats.zscore(df[col]))
    filtered_entries = (zscore < 3) & filtered_entries

df = df[filtered_entries]

print(f'Jumlah baris setelah memfilter outlier: {len(df)}')

"""## GROUP THE DATA"""

df_before_grouped = df

df = df_before_grouped.groupby(['CustomerID']).agg({'TransactionID':'count', 'Qty': 'sum', 'TotalAmount': 'sum'}).reset_index()

df.head()

"""## STANDARDIZATION"""

# Standardize the columns because k-means works better when the data have mean of 0 and std of 1
# this is because k-means uses distance measurement

# Check data distribution first (if it is bell shaped then its gaussian/normal, therefore we can standardize it)
plt.subplot(1, 3, 1)
plt.hist(df['TransactionID'])
plt.plot()

plt.subplot(1, 3, 2)
plt.hist(df['Qty'])
plt.plot()

plt.subplot(1, 3, 3)
plt.hist(df['TotalAmount'])
plt.plot()

# All columns have gaussian/normal data distribution so we can standardize it
from sklearn.preprocessing import MinMaxScaler, StandardScaler

df['TransactionID'] = StandardScaler().fit_transform(df['TransactionID'].values.reshape(len(df), 1))
df['Qty'] = StandardScaler().fit_transform(df['Qty'].values.reshape(len(df), 1))
df['TotalAmount'] = StandardScaler().fit_transform(df['TotalAmount'].values.reshape(len(df), 1))

"""# CLUSTERING MODEL

## WITH TRANSACTIONID

### FIND OPTIMAL CLUSTER NUMBER
"""

X1 = df[['CustomerID', 'TransactionID']]
wcss=[]
for n in range(1, 11):
  model1 = KMeans(n_clusters=n, init='k-means++', n_init=10, max_iter=300, tol=0.0001, random_state=100)
  model1.fit(X1)
  wcss.append(model1.inertia_)
print(wcss)

plt.figure(figsize=(8, 3))
plt.plot(list(range(1,11)), wcss, color='royalblue', marker='o', linewidth=2, markersize=12, markerfacecolor='m',markeredgecolor='m')
plt.title('WCSS vs. Banyaknya Cluster', fontsize=18)
plt.xlabel('Jumlah Cluster', fontsize=15)
plt.ylabel('WCSS', fontsize=15)
plt.show()

# The WCSS is not changing drastically anymore on 3, therefore num of clusters are 3

"""### MAKE MODEL"""

model1=KMeans(n_clusters=3, init='k-means++', n_init=10, max_iter=300, tol=0.0001, random_state=100)
model1.fit(X1)
labels1=model1.labels_
centroids1=model1.cluster_centers_

plt.figure(figsize=(11,6))
sns.set_style('white')
plt.scatter(x=df['CustomerID'], y=df['TransactionID'], c=labels1, cmap='winter')
plt.scatter(x = centroids1[: , 0], y = centroids1[: , 1], s=300, c='red')
plt.xlabel('Customer ID', fontsize=15)
plt.ylabel('Transaction Count', fontsize=15)
plt.title('Segmentasi Pelanggan berdasarkan Customer ID dan Transaction Count', fontsize=18)
plt.show()

"""### EVALUATE MODEL"""

# The closer to 1, the better the model is
from sklearn.metrics import silhouette_score

score1 = silhouette_score(df, labels1)
print('Silhouetter Score: %.3f' % score1)

"""## WITH QTY

### FIND OPTIMAL CLUSTER NUMBER
"""

X2 = df[['CustomerID', 'Qty']]
wcss=[]
for n in range(1, 11):
  model2 = KMeans(n_clusters=n, init='k-means++', n_init=10, max_iter=300, tol=0.0001, random_state=100)
  model2.fit(X2)
  wcss.append(model2.inertia_)
print(wcss)

plt.figure(figsize=(8, 3))
plt.plot(list(range(1,11)), wcss, color='royalblue', marker='o', linewidth=2, markersize=12, markerfacecolor='m',markeredgecolor='m')
plt.title('WCSS vs. Banyaknya Cluster', fontsize=18)
plt.xlabel('Jumlah Cluster', fontsize=15)
plt.ylabel('WCSS', fontsize=15)
plt.show()

# The WCSS is not changing drastically anymore on 3, therefore num of clusters are 3

"""### MAKE MODEL"""

model2=KMeans(n_clusters=3, init='k-means++', n_init=10, max_iter=300, tol=0.0001, random_state=100)
model2.fit(X2)
labels2=model2.labels_
centroids2=model2.cluster_centers_

plt.figure(figsize=(11,6))
sns.set_style('white')
plt.scatter(x=df['CustomerID'], y=df['Qty'], c=labels2, cmap='winter')
plt.scatter(x = centroids2[: , 0], y = centroids2[: , 1], s=300, c='red')
plt.xlabel('Customer ID', fontsize=15)
plt.ylabel('Qty Sum', fontsize=15)
plt.title('Segmentasi Pelanggan berdasarkan Customer ID dan Qty', fontsize=18)
plt.show()

"""### EVALUATE MODEL"""

# The closer to 1, the better the model is
from sklearn.metrics import silhouette_score

score2 = silhouette_score(df, labels2)
print('Silhouetter Score: %.3f' % score2)

"""## WITH TOTAL AMOUNT

### FIND OPTIMAL CLUSTER NUMBER
"""

X3 = df[['CustomerID', 'TotalAmount']]
wcss=[]
for n in range(1, 11):
  model3 = KMeans(n_clusters=n, init='k-means++', n_init=10, max_iter=300, tol=0.0001, random_state=100)
  model3.fit(X3)
  wcss.append(model3.inertia_)
print(wcss)

plt.figure(figsize=(8, 3))
plt.plot(list(range(1,11)), wcss, color='royalblue', marker='o', linewidth=2, markersize=12, markerfacecolor='m',markeredgecolor='m')
plt.title('WCSS vs. Banyaknya Cluster', fontsize=18)
plt.xlabel('Jumlah Cluster', fontsize=15)
plt.ylabel('WCSS', fontsize=15)
plt.show()

# The WCSS is not changing drastically anymore on 3, therefore num of clusters are 3

"""### MAKE MODEL"""

model3=KMeans(n_clusters=3, init='k-means++', n_init=10, max_iter=300, tol=0.0001, random_state=100)
model3.fit(X3)
labels3=model3.labels_
centroids3=model3.cluster_centers_

plt.figure(figsize=(11,6))
sns.set_style('white')
plt.scatter(x=df['CustomerID'], y=df['TotalAmount'], c=labels3, cmap='winter')
plt.scatter(x = centroids3[: , 0], y = centroids3[: , 1], s=300, c='red')
plt.xlabel('Customer ID', fontsize=15)
plt.ylabel('Total Amount', fontsize=15)
plt.title('Segmentasi Pelanggan berdasarkan Customer ID dan Qty', fontsize=18)
plt.show()

"""### EVALUATE MODEL"""

# The closer to 1, the better the model is
from sklearn.metrics import silhouette_score

score3 = silhouette_score(df, labels3)
print('Silhouetter Score: %.3f' % score3)